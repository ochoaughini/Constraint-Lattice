"""Profanity filter constraint.

Replaces banned words with asterisks (***). This is a simple example of
real-world constraint logic. The banned word list can be loaded from an
external source or configured per deployment; here we embed a minimal list for
demo purposes.
"""

from __future__ import annotations

from engine.scheduler import constraint

import re


@constraint(priority=90, tags=["safety"])
class ConstraintProfanityFilter:
    """Replace profane words with asterisks before content is returned."""

    _BANNED_WORDS = [
        "shit",
        "fuck",
        "asshole",
        "bitch",
    ]

    _REGEX = re.compile(
        r"|".join(rf"\b{re.escape(w)}\b" for w in _BANNED_WORDS), re.IGNORECASE
    )

    def filter_constraint(self, prompt: str, output: str) -> str:
        """Mask profane words in *output*.

        Parameters
        ----------
        prompt:
            The original prompt (unused, but part of the canonical signature).
        output:
            The text generated by the model so far.

        Returns
        -------
        str
            Mutated string where banned words are replaced by `***`.
        """
        return self._REGEX.sub("***", output)
